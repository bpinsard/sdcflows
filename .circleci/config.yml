version: 2.1
orbs:
  docker: circleci/docker@1.6.0

jobs:
  cache_test_data:
    docker:
      - image: cimg/python:3.9.16
    working_directory: /tmp/data
    environment:
      - TEMPLATEFLOW_HOME: /tmp/templateflow
    steps:
      - restore_cache:
          keys:
            - env-v2-{{ .Branch }}-
            - env-v2-maint/1.3.x-
            - env-v2-
      - restore_cache:
          keys:
            - data-v2-{{ .Branch }}-
            - data-v2-maint/1.3.x-
            - data-v2-

      - run:
          name: Setup git-annex
          command: |
            if [[ ! -d /usr/lib/git-annex.linux ]]; then
              wget -O- http://neuro.debian.net/lists/jammy.us-nh.full | sudo tee /etc/apt/sources.list.d/neurodebian.sources.list
              sudo apt-key adv --recv-keys --keyserver hkps://keyserver.ubuntu.com 0xA5D32F012649A5A9
              sudo apt-get update && sudo apt-get install -y --no-install-recommends git-annex-standalone
            fi
            git config --global user.name 'NiPreps Bot'
            git config --global user.email 'nipreps@gmail.com'

      - run:
          name: Setup DataLad & TemplateFlow
          command: |
            pip install --no-cache-dir -U pip
            pip install --no-cache-dir -U datalad
            pip install --no-cache-dir -U templateflow
            python -c "from templateflow import api as tfapi; \
                       tfapi.get('MNI152NLin2009cAsym', resolution=2, desc='brain', suffix='mask'); \
                       tfapi.get('MNI152NLin2009cAsym', resolution=2, desc='fMRIPrep', suffix='boldref');"

      - save_cache:
          key: env-v2-{{ .Branch }}-{{ .BuildNum }}
          paths:
            - /tmp/cache/git-annex-standalone.tar.gz
            - /usr/bin/git-annex
            - /usr/bin/git-annex-shell
            - /usr/lib/git-annex.linux

      - run:
          name: Install ds001600
          command: |
            datalad install https://github.com/OpenNeuroDatasets/ds001600.git
            datalad update --merge -d ds001600/
            datalad get -r -d ds001600/
      - run:
          name: Get testdata
          command: |
            if [[ ! -d /tmp/data/testdata ]]; then
              wget --retry-connrefused --waitretry=5 --read-timeout=20 --timeout=15 -t 0 -q \
                  -O testdata.zip "https://files.osf.io/v1/resources/9sy2a/providers/osfstorage/5d44b940bcd6d900198ed6be/?zip="
              unzip testdata.zip -d /tmp/data/testdata
            fi
      - save_cache:
          key: data-v2-{{ .Branch }}-{{ .BuildNum }}
          paths:
            - /tmp/data
            - /tmp/templateflow

      - restore_cache:
          keys:
            - freesurfer-v0-{{ .BuildNum }}
            - freesurfer-v0-
      - run:
          name: Pull FreeSurfer down
          command: |
            if [[ ! -d /tmp/freesurfer ]]; then
              curl -sSL https://surfer.nmr.mgh.harvard.edu/pub/dist/freesurfer/6.0.1/freesurfer-Linux-centos6_x86_64-stable-pub-v6.0.1.tar.gz | tar zxv --no-same-owner -C /tmp \
                   --exclude='freesurfer/diffusion' \
                   --exclude='freesurfer/docs' \
                   --exclude='freesurfer/fsfast' \
                   --exclude='freesurfer/lib/cuda' \
                   --exclude='freesurfer/lib/qt' \
                   --exclude='freesurfer/matlab' \
                   --exclude='freesurfer/mni/share/man' \
                   --exclude='freesurfer/subjects/fsaverage_sym' \
                   --exclude='freesurfer/subjects/fsaverage3' \
                   --exclude='freesurfer/subjects/fsaverage4' \
                   --exclude='freesurfer/subjects/cvs_avg35' \
                   --exclude='freesurfer/subjects/cvs_avg35_inMNI152' \
                   --exclude='freesurfer/subjects/bert' \
                   --exclude='freesurfer/subjects/lh.EC_average' \
                   --exclude='freesurfer/subjects/rh.EC_average' \
                   --exclude='freesurfer/subjects/sample-*.mgz' \
                   --exclude='freesurfer/subjects/V1_average' \
                   --exclude='freesurfer/trctrain'
              echo "b2VzdGViYW5Ac3RhbmZvcmQuZWR1CjMwNzU2CiAqQ1MzYkJ5VXMxdTVNCiBGU2kvUGJsejJxR1V3Cg==" | base64 -d > /tmp/freesurfer/license.txt
            else
              echo "FreeSurfer was cached."
              circleci step halt
            fi
      - save_cache:
          key: freesurfer-v0-{{ .BuildNum }}
          paths:
            - /tmp/freesurfer

  build_n_pytest:
    machine:
      image: ubuntu-2204:2022.10.2
    working_directory: /tmp/src/sdcflows
    environment:
      TZ: "/usr/share/zoneinfo/America/Los_Angeles"
    steps:
      - checkout:
          path: /tmp/src/sdcflows
      - restore_cache:
          keys:
            - build-v3-{{ .Branch }}-{{ epoch }}
            - build-v3-{{ .Branch }}-
            - build-v3-maint/1.3.x-
          paths:
            - /tmp/docker
      - run:
          name: Set-up a Docker registry
          command: |
            docker run -d -p 5000:5000 --restart=always --name=registry \
                -v /tmp/docker:/var/lib/registry registry:2
      - run:
          name: Pull images
          command: |
            set +e
            docker pull localhost:5000/ubuntu
            success=$?
            set -e
            if [[ "$success" = "0" ]]; then
                echo "Pulling from local registry"
                docker tag localhost:5000/ubuntu ubuntu:xenial-20191010
                docker pull localhost:5000/sdcflows
                docker tag localhost:5000/sdcflows nipreps/sdcflows:latest
                docker tag localhost:5000/sdcflows nipreps/sdcflows
            else
                LATEST=$( git describe --abbrev=0 )
                docker pull ubuntu:xenial-20191010
                docker tag ubuntu:xenial-20191010 localhost:5000/ubuntu
                docker push localhost:5000/ubuntu
                if docker pull nipreps/sdcflows:$LATEST; then
                    echo "Pulling nipreps/sdcflows:$LATEST from Docker Hub"
                    docker tag nipreps/sdcflows:$LATEST nipreps/sdcflows:latest
                else
                    echo "Falling back to nipreps/sdcflows:1.3.3"
                    docker pull nipreps/sdcflows:1.3.3
                    docker tag nipreps/sdcflows:1.3.3 nipreps/sdcflows:latest
                fi
            fi
      - run:
          name: Build Docker image
          no_output_timeout: 60m
          command: |
            python3 -m pip install --upgrade pip
            python3 -m pip install --upgrade "setuptools_scm[toml]"

            # Get version, update files.
            THISVERSION=$( python3 -m setuptools_scm )
            if [[ ${THISVERSION:0:1} == "0" ]] ; then
              echo "WARNING: latest git tag could not be found"
              echo "Please, make sure you fetch all tags from upstream with"
              echo "the command ``git fetch --tags --verbose`` and push"
              echo "them to your fork with ``git push origin --tags``"
            fi
            # Build docker image
            e=1 && for i in {1..5}; do
              docker build --rm \
                --cache-from=nipreps/sdcflows \
                -t nipreps/sdcflows:latest \
                --build-arg BUILD_DATE=`date -u +"%Y-%m-%dT%H:%M:%SZ"` \
                --build-arg VCS_REF=`git rev-parse --short HEAD` \
                --build-arg VERSION="${CIRCLE_TAG:-$THISVERSION}" . \
              && e=0 && break || sleep 15
            done && [ "$e" -eq "0" ]
            echo "${CIRCLE_TAG:-$THISVERSION}" >> /tmp/.local-version.txt
      - run:
          name: Docker push to local registry
          no_output_timeout: 40m
          command: |
            docker tag nipreps/sdcflows:latest localhost:5000/sdcflows
            docker push localhost:5000/sdcflows
      - run:
          name: Docker registry garbage collection
          command: |
            docker exec -it registry /bin/registry garbage-collect --delete-untagged \
                /etc/docker/registry/config.yml
      - save_cache:
          key: build-v3-{{ .Branch }}-{{ epoch }}
          paths:
            - /tmp/docker
      - run:
          name: Check version packaged in Docker image
          command: |
              docker run --rm -v /tmp:/tmp -v /tmp/src/sdcflows/.circleci/version.py:/usr/share/version.py \
                     --entrypoint=python nipreps/sdcflows /usr/share/version.py
              THISVERSION=$( head -n1 /tmp/.local-version.txt )
              INSTALLED_VERSION=$( head -n1 /tmp/.docker-version.txt )
              echo "VERSION: \"${THISVERSION}\""
              echo "INSTALLED: \"${INSTALLED_VERSION}\""
              test "${INSTALLED_VERSION}" = "${THISVERSION}"

      - restore_cache:
          keys:
            - freesurfer-v0-{{ .BuildNum }}
            - freesurfer-v0-
      - restore_cache:
          keys:
            - data-v2-{{ .Branch }}-
            - data-v2-maint/1.3.x-
            - data-v2-
      - restore_cache:
          keys:
            - workdir-v2-{{ .Branch }}-
            - workdir-v2-maint/1.3.x-
            - workdir-v2-
      - run:
          name: Refreshing cached intermediate results
          command: |
            COMMIT_MSG=$( git log --format=oneline -n 1 $CIRCLE_SHA1 )
            set +e
            do_refresh="$( echo "${COMMIT_MSG}" | grep -i -E '\[refresh[ _]?cache\]' )"
            set -e
            if [[ "x${do_refresh}" = "x" ]]; then
              echo "Did not refresh the workdir."
            else
              wget --retry-connrefused --waitretry=5 --read-timeout=20 --timeout=15 -t 0 -q \
                  -O /tmp/data/workdir.tar.gz "https://files.osf.io/v1/resources/9sy2a/providers/osfstorage/5dcabd60a1cd9e000c751b3c"
              rm -rf /tmp/work
              mkdir -p /tmp/work
              pushd /tmp/work
              tar xzfv /tmp/data/workdir.tar.gz --strip 1
              popd
            fi

            wipe_dir=$( echo "${COMMIT_MSG}" | sed -n 's/.*\[wipe \([a-zA-Z0-9_\*]*\)\].*/\1/p' )
            if [[ "x${wipe_dir}" != "x" ]]; then
              path=/tmp/work/${wipe_dir}
              echo "Found tag [wipe ${wipe_dir}] - clearing up $path ..."
              rm -rf ${path}
            fi
      - run:
          name: Run tests
          no_output_timeout: 2h
          command: |
            mkdir -p /tmp/work
            docker run -it --rm -e TEST_DATA_HOME=/data/ -e TEST_OUTPUT_DIR=/out \
                   -v /tmp/freesurfer:/opt/freesurfer:ro -e FS_LICENSE=/opt/freesurfer/license.txt \
                   -v /tmp/work:/work -e TEST_WORK_DIR=/work \
                   -v /tmp/templateflow:/home/sdcflows/.cache/templateflow \
                   -v /tmp/data:/data:ro -v /tmp/src:/src -v /tmp/tests:/out \
                   -w /src/sdcflows nipreps/sdcflows:latest \
                   pytest -v --junit-xml=/out/pytest.xml sdcflows/
      - save_cache:
          key: workdir-v2-{{ .Branch }}-{{ .BuildNum }}
          paths:
            - /tmp/work
      - store_artifacts:
          path: /tmp/tests
      - store_test_results:
          path: /tmp/tests

  deploy_docker:
    machine:
      image: ubuntu-2204:2022.10.2
    working_directory: /tmp/src/
    steps:
      - restore_cache:
          keys:
            - build-v3-{{ .Branch }}-{{ epoch }}
            - build-v3-{{ .Branch }}-
            - build-v3-maint/1.3.x-
            - build-v3-
          paths:
            - /tmp/docker
      - run:
          name: Set-up a Docker registry
          command: |
            docker run -d -p 5000:5000 --restart=always --name=registry \
                -v /tmp/docker:/var/lib/registry registry:2
      - run:
          name: Pull images from local registry
          command: |
            docker pull localhost:5000/sdcflows
            docker tag localhost:5000/sdcflows nipreps/sdcflows:latest
      - run:
          name: Deploy to Docker Hub
          no_output_timeout: 40m
          command: |
            if [[ -n "$DOCKER_PAT" ]]; then
              docker login -u $DOCKER_USER -p $DOCKER_PAT
              docker tag nipreps/sdcflows nipreps/sdcflows:$CIRCLE_TAG
              docker push nipreps/sdcflows:$CIRCLE_TAG
            fi

  test_package:
    docker:
      - image: cimg/python:3.9.16
    working_directory: /tmp/src/sdcflows
    steps:
      - checkout
      - run:
          name: Prepare environment & build
          command: |
            python3 -m venv /tmp/buildenv
            source /tmp/buildenv/bin/activate
            python3 -m pip install --upgrade pip build twine
            python3 -m build
            twine check dist/sdcflows*
      - store_artifacts:
          path: /tmp/src/sdcflows/dist
      - persist_to_workspace:
          root: /tmp/src/sdcflows
          paths: dist
      - run:
          name: Install on separate environment and check version [sdist]
          command: |
            python3 -m venv /tmp/install_sdist
            source /tmp/install_sdist/bin/activate
            python3 -m pip install --upgrade pip setuptools_scm
            THISVERSION=$( python3 -m setuptools_scm )
            THISVERSION=${CIRCLE_TAG:-$THISVERSION}
            python3 -m pip install dist/sdcflows*.tar.gz
            INSTALLED_VERSION=$(python3 -c 'import sdcflows as sdc; print(sdc.__version__, end="")')
            echo "VERSION: \"${THISVERSION}\""
            echo "INSTALLED: \"${INSTALLED_VERSION}\""
            test "${INSTALLED_VERSION}" = "${THISVERSION}"
      - run:
          name: Install on separate environment and check version [wheel]
          command: |
            python3 -m venv /tmp/install_wheel
            source /tmp/install_wheel/bin/activate
            python3 -m pip install --upgrade pip setuptools_scm
            THISVERSION=$( python3 -m setuptools_scm )
            THISVERSION=${CIRCLE_TAG:-$THISVERSION}
            python3 -m pip install dist/sdcflows*.whl
            INSTALLED_VERSION=$(python3 -c 'import sdcflows as sdc; print(sdc.__version__, end="")')
            echo "VERSION: \"${THISVERSION}\""
            echo "INSTALLED: \"${INSTALLED_VERSION}\""
            test "${INSTALLED_VERSION}" = "${THISVERSION}"

  deploy_pypi:
    docker:
      - image: cimg/python:3.9.16
    working_directory: /tmp/src/sdcflows
    steps:
      - attach_workspace:
          at: /tmp/src/sdcflows
      - run:
          name: Upload to Pypi
          command: |
            python3 -m venv /tmp/upload
            source /tmp/upload/bin/activate
            python3 -m pip install twine
            python3 -m twine check dist/*
            python3 -m twine upload dist/* --non-interactive

workflows:
  version: 2
  build_deploy:
    jobs:
      - cache_test_data:
          context:
            - nipreps-common
            - fs-license
          filters:
            branches:
              ignore:
                - /docs?\/.*/
            tags:
              only: /.*/

      - build_n_pytest:
          requires:
            - cache_test_data
          filters:
            branches:
              ignore:
                - /docs?\/.*/
            tags:
              only: /.*/

      - test_package:
          context:
            - nipreps-common
          filters:
            branches:
              ignore:
                - /docs?\/.*/
                - /tests?\/.*/
            tags:
              only: /.*/

      - deploy_pypi:
          context:
            - nipreps-common
          requires:
            - test_package
            - build_n_pytest
          filters:
            branches:
              ignore: /.*/
            tags:
              only: /.*/

      - deploy_docker:
          context:
            - nipreps-common
          requires:
            - deploy_pypi
          filters:
            branches:
              ignore: /.*/
            tags:
              only: /.*/
